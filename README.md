# MSFANet
To address the issue of insufficient resolution in remote sensing images due to limita-tions in sensors and transmission, this paper proposes a multi-scale feature fusion model, MSFANet, based on the Swin Transformer architecture for remote sensing im-age super-resolution reconstruction. The model comprises three main modules: shallow feature extraction, deep feature extraction, and high-quality image reconstruction. The deep feature extraction module innovatively introduces three core components: Feature Refinement Augmentation (FRA), Local Structure Optimization (LSO), and Residual Fusion Network (RFN), which effectively extract and adaptively aggregate multi-scale information from local to global levels. Experiments on three public remote sensing datasets (RSSCN7, AID, and WHU-RS19) compare MSFANet with nine mainstream models (HSENet, TransENet, etc.) for ×2, ×3, and ×4 super-resolution tasks.  Results show that MSFANet outperforms the compared models in five evaluation metrics, in-cluding Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM).  Furthermore, compared to models like ASID and BSRAW, MSFANet achieves higher reconstruction quality with reduced memory consumption, balancing efficiency and performance, thus providing an effective solution for remote sensing image su-per-resolution tasks.
